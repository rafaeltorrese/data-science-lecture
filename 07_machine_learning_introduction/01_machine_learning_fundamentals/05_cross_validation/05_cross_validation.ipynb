{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9391ff93",
   "metadata": {},
   "source": [
    "<center><h1>Validación cruzada</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9fdef",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "La validación de entrenamiento/prueba es una técnica simple para probar la precisión de un modelo de aprendizaje automático en datos nuevos en los que el modelo no fue entrenado. Ahora, nos centraremos en técnicas más sólidas.\n",
    "\n",
    "Para empezar, nos centraremos en la técnica de **validación por exclusión (holdout validation)**, que implica:\n",
    "\n",
    "- dividir el conjunto de datos completo en 2 particiones:\n",
    "    - un conjunto de entrenamiento\n",
    "    - un conjunto de prueba\n",
    "- entrenar el modelo en el conjunto de entrenamiento,\n",
    "- usar el modelo entrenado para predecir etiquetas en el conjunto de prueba,\n",
    "- calcular una métrica de error para comprender la efectividad del modelo,\n",
    "- cambiar los conjuntos de entrenamiento y prueba y repita,\n",
    "- promediar los errores.\n",
    "\n",
    "En la validación por exclusión, generalmente usamos una división 50/50 en lugar de la división 75/25 de la validación de entrenamiento/prueba. De esta forma, eliminamos el número de observaciones como fuente potencial de variación en el rendimiento de nuestro modelo.\n",
    "\n",
    "<img src=\"figs/holdout_validation.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "\n",
    "Comencemos por dividir el conjunto de datos en 2 mitades casi equivalentes.\n",
    "\n",
    "Cuando divida el conjunto de datos, no olvide configurar una copia usando `.copy()` para asegurarse de no obtener resultados inesperados más adelante. Si ejecuta el código localmente en Jupyter Notebook o Jupyter Lab sin `.copy()`, notará lo que se conoce como Advertencia de configuración con copia. Esto no evitará que su código se ejecute correctamente, pero le permite saber que cualquier operación que esté haciendo está tratando de establecerse en una copia de un segmento de un dataframe. Para asegurarse de que no vea esta advertencia, asegúrese de incluir `.copy()` cada vez que realice operaciones en un dataframe.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Utilice la función `numpy.random.permutation()` para aleatorizar el orden de las filas en `dc_listings`.\n",
    "- Seleccione las primeras 1862 filas y asígnelas a `split_one`.\n",
    "- Seleccione las 1861 filas restantes y asígnelas a `split_two`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b7afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ec1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfcefb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc_listings['price'] = dc_listings['price'].str.replace('[\\$,]', '', regex=True).astype('float')\n",
    "\n",
    "print(len(dc_listings) / 2, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8de0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = dc_listings.iloc[np.random.default_rng(2021).permutation(len(dc_listings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d563722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_one = dc_listings.iloc[:1862].copy()\n",
    "split_two = dc_listings.iloc[1862:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1af6b",
   "metadata": {},
   "source": [
    "## 2. Holdout Validation\n",
    "Ahora que hemos dividido nuestro conjunto de datos en 2 dataframes, hagamos lo siguiente:\n",
    "\n",
    "- entrenar un modelo de k-vecinos más cercanos en la primera mitad,\n",
    "- probar este modelo en la segunda mitad,\n",
    "- entrenar un modelo de k-vecinos más cercanos en la segunda mitad,\n",
    "- probar este modelo en la primera mitad.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Entrene un modelo de k-vecinos más cercanos utilizando el algoritmo predeterminado (`auto`) y el número predeterminado de vecinos (`5`) que:\n",
    "     - Utiliza la columna `accommodates` de `train_one` para entrenar y\n",
    "     - Lo prueba en `test_one`.\n",
    "- Asigne el valor RMSE resultante a `iteration_one_rmse`.\n",
    "- Entrene un modelo de k-vecinos más cercanos utilizando el algoritmo predeterminado (`auto`) y el número predeterminado de vecinos (`5`) que:\n",
    "     - Utiliza la columna `accommodates` de `test_two` para entrenar y\n",
    "     - Lo prueba en `test_two`.\n",
    "- Asigne el valor RMSE resultante a `iteration_two_rmse`.\n",
    "- Use `numpy.mean()` para calcular el promedio de los 2 valores RMSE y asigne a `avg_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af3dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d676940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsRegressor()\n",
    "knn1.fit(train_one[['accommodates']], train_one[['price']])\n",
    "predictions1 = knn1.predict(test_one[['accommodates']])\n",
    "iteration_one_rmse = np.sqrt(mean_squared_error(predictions1, test_one['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e1f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsRegressor()\n",
    "knn2.fit(train_two[['accommodates']], train_two['price'])\n",
    "predictions2 = knn2.predict(test_two[['accommodates']])\n",
    "iteration_two_rmse = np.sqrt(mean_squared_error(predictions2, test_two['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d7cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.70692056945418\n",
      "125.33395047116689\n"
     ]
    }
   ],
   "source": [
    "print(iteration_one_rmse)\n",
    "print(iteration_two_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3deda56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.02043552031054\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = np.mean([iteration_one_rmse, iteration_two_rmse])\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adce35",
   "metadata": {},
   "source": [
    "## 3. Validación cruzada K-Fold\n",
    "\n",
    "Si promediamos los dos valores RMSE del último paso, obtenemos un valor RMSE de aproximadamente 127.02. La validación por exclusión (holdout validation) es en realidad un ejemplo específico de una clase más grande de técnicas de validación llamada validación cruzada k-fold. \n",
    "\n",
    "Si bien la validación de exclusión es mejor que la validación de entrenamiento/prueba porque el modelo no está sesgado repetidamente hacia un subconjunto específico de datos, ambos modelos entrenados solo usan la mitad de los datos disponibles. La validación cruzada K-fold, por otro lado, aprovecha una mayor proporción de los datos durante el entrenamiento mientras sigue rotando a través de diferentes subconjuntos de datos para evitar los problemas de validación de entrenamiento/prueba.\n",
    "\n",
    "Aquí está el algoritmo de la validación cruzada de k-fold:\n",
    "\n",
    "- dividir el conjunto de datos completo en `k` particiones de igual longitud.\n",
    "    - seleccionando las `k-1` particiones  como el conjunto de entrenamiento y\n",
    "    - seleccionando la partición restante como el conjunto de prueba\n",
    "- entrenar el modelo en el conjunto de entrenamiento.\n",
    "- usar el modelo entrenado para predecir etiquetas en el conjunto de prueba.\n",
    "- calcular la métrica de error del conjunto prueba.\n",
    "- repetir todos los pasos anteriores `k-1` veces, hasta que cada partición se haya utilizado como conjunto de prueba para una iteración.\n",
    "- calcular la media de los valores de error `k`.\n",
    "\n",
    "La validación de exclusión es esencialmente una versión de la validación cruzada k-fold cuando `k` es igual a `2`. En general, los pliegues (número de subconjuntos) de `5` o `10` se utilizan para la validación cruzada k-fold. Aquí hay un diagrama que describe cada iteración de la validación cruzada de 5 subconjuntos:\n",
    "\n",
    "<img src=\"figs/kfold_cross_validation.png\" width=\"800\" height=\"600\" />\n",
    "\n",
    "A medida que aumenta el número de pliegues, el número de observaciones en cada pliegue (subconjunto) disminuye y la varianza de los errores entre cada pliegue aumenta. \n",
    "\n",
    "Comencemos dividiendo manualmente el conjunto de datos en 5 pliegues. En lugar de dividir en 5 dataframes, agreguemos una columna que especifique a qué subconjunto pertenece la fila. De esta manera, podemos seleccionar fácilmente nuestro conjunto de entrenamiento y nuestro conjunto de prueba.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Agregue una nueva columna a `dc_listings` llamada `fold` que contiene el número de subconjunto al que pertenece cada fila:\n",
    "- El pliegue `1` debe tener filas desde el índice `0` hasta `745`, sin incluir `745`.\n",
    "- El pliegue `2` debe tener filas desde el índice `745` hasta `1490`, sin incluir `1490`.\n",
    "- El pliegue `3` debe tener filas desde el índice `1490` hasta `2234`, sin incluir `2234`.\n",
    "- El pliegue `4` debe tener filas desde el índice `2234` hasta `2978`, sin incluir `2978`.\n",
    "- El pliegue `5` debe tener filas desde el índice `2978` hasta `3723`, sin incluir `3723`.\n",
    "- Asegúrate de que el tipo de `fold` sea un tipo flotante.\n",
    "- Cuente los valores únicos para la columna `fold` para confirmar que cada pliegue tiene aproximadamente la misma cantidad de elementos.\n",
    "- Muestra el número de valores faltantes (missing values) en la columna `fold` para confirmar que no nos falta ninguna fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8eec355",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings.loc[dc_listings.index[:745], 'fold'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd16188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604     1.0\n",
       "2493    1.0\n",
       "904     1.0\n",
       "1935    1.0\n",
       "544     1.0\n",
       "       ... \n",
       "2127    NaN\n",
       "3388    NaN\n",
       "1769    NaN\n",
       "1333    NaN\n",
       "3412    NaN\n",
       "Name: fold, Length: 3723, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2375faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings.loc[dc_listings.index[745:1490], 'fold'] = 2\n",
    "dc_listings.loc[dc_listings.index[1490:2234], 'fold'] = 3\n",
    "dc_listings.loc[dc_listings.index[2234:2978], 'fold'] = 4\n",
    "dc_listings.loc[dc_listings.index[2978:], 'fold'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0503b59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    745\n",
       "2.0    745\n",
       "3.0    744\n",
       "4.0    744\n",
       "5.0    745\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings['fold'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bb8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_listings['fold'] = 1.0\n",
    "# dc_listings.fold.iloc[745:1490] = 2\n",
    "# dc_listings.fold.iloc[1490:2234] = 3\n",
    "# dc_listings.fold.iloc[2234:2978] = 4\n",
    "# dc_listings.fold.iloc[2978:] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba851bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dc_listings['fold'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eadce7",
   "metadata": {},
   "source": [
    "## 4. Primera iteración\n",
    "\n",
    "Comencemos por realizar la primera iteración de la validación cruzada de k-fold en un modelo univariado.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Entrene un modelo de k-vecinos más cercanos usando la columna `accommodates` como la única característica de los pliegues `2` a `5` como conjunto de entrenamiento.\n",
    "- Use el modelo para hacer predicciones en el conjunto de prueba (columna `accommodates` del subconjunto `1`) y asigne las etiquetas pronosticadas a `labels`.\n",
    "- Calcule el valor RMSE comparando la columna `price` con las etiquetas pronosticadas.\n",
    "- Asigne el valor RMSE a `iteration_one_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8d8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "print(dc_listings[dc_listings['fold'] != 1]['fold'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6009afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = dc_listings[dc_listings['fold'] != 1].copy()\n",
    "test_df = dc_listings[dc_listings['fold'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330bf188",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(training_df[['accommodates']], training_df['price'])\n",
    "labels = knn.predict(test_df[['accommodates']])\n",
    "iteration_one_rmse = np.sqrt(mean_squared_error(labels, test_df['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4130b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.45677104635922\n"
     ]
    }
   ],
   "source": [
    "print(iteration_one_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3cb44",
   "metadata": {},
   "source": [
    "## 5. Función para entrenar modelos\n",
    "\n",
    "Desde la primera iteración, logramos un valor RMSE de aproximadamente **111**. Calculemos los valores RMSE para las iteraciones restantes. Para facilitar el proceso de iteración, coloquemos el código que escribimos anteriormente en una función.\n",
    "\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Escriba una función llamada `train_and_validate` que tome un dataframe como primer parámetro (`df`) y una lista de valores de subconjuntos (`1` a `5` en nuestro caso) como segundo parámetro (`folds`). Esta función debería:\n",
    "    - Entrenar modelos `n` (donde `n` es el número de subconjuntos) y realizar una validación cruzada k-fold (usando `n` subconjuntos). Utilice el valor `k` predeterminado para la clase `KNeighborsRegressor`.\n",
    "    - Devuelva una lista de valores RMSE, donde el primer elemento es el RMSE cuando el subconjunto `1` fue el conjunto de prueba, el segundo elemento es el RMSE para cuando el subconjunto `2` fue el conjunto de prueba, y así sucesivamente.\n",
    "- Use la función `train_and_validate` para devolver la lista de valores RMSE para el dataframe `dc_listings` y asigne a `rmses`.\n",
    "- Calcular la media de estos valores y asignar a `avg_rmse`.\n",
    "- Mostrar tanto `rmses` como `avg_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3c7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(df, folds):\n",
    "    rmses = []\n",
    "    \n",
    "    for n in folds:\n",
    "        training_df = df[df['fold'] != n].copy()\n",
    "        test_df = df[df['fold'] == n].copy()\n",
    "\n",
    "        knn = KNeighborsRegressor() \n",
    "        knn.fit(training_df[['accommodates']], training_df['price'])\n",
    "\n",
    "        labels = knn.predict(test_df[['accommodates']])\n",
    "        rmses.append(np.sqrt(mean_squared_error(labels, test_df['price'])))\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99c17e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = train_and_validate(dc_listings, folds=[1, 2, 3, 4, 5])\n",
    "avg_rmse = np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8c25a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111.45677104635922, 123.78106565531378, 178.30716142994456, 153.87714325088623, 155.0998542182535]\n",
      "144.50439912015148\n"
     ]
    }
   ],
   "source": [
    "print(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113116e",
   "metadata": {},
   "source": [
    "## 6. Realización de la validación cruzada K-Fold con Scikit-Learn\n",
    "\n",
    "Si bien el valor promedio de RMSE fue de aproximadamente **135**, los valores de RMSE oscilaron entre **102** y **159+**. Esta gran cantidad de variabilidad entre los valores RMSE significa que estamos usando un modelo deficiente o un criterio de evaluación deficiente (¡o un poco de ambos!). Al implementar su propia función de validación cruzada k-fold, es de esperar que hayas adquirido una buena comprensión del funcionamiento interno de la técnica. \n",
    "\n",
    "La función que escribimos, sin embargo, tiene muchas limitaciones. Si ahora queremos cambiar la cantidad de pliegues(subconjuntos) que deseamos usar, debemos hacer que la función sea más general para que también pueda manejar la ordenación aleatoria de las filas en el dataframe y la división en subconjuntos.\n",
    "\n",
    "En el aprendizaje automático, estamos interesados en construir un buen modelo y comprender con precisión qué tan bien funcionará. Para construir un mejor modelo de k-vecinos más cercanos, podemos cambiar las características(variables) que usa o ajustar la cantidad de vecinos (un hiperparámetro). Para comprender con precisión el rendimiento de un modelo, podemos realizar una validación cruzada k-fold y seleccionar el número adecuado de pliegues. Hemos aprendido cómo scikit-learn nos facilita experimentar rápidamente con estas diferentes configuranciones cuando se trata de construir un mejor modelo. Ahora profundicemos en cómo podemos usar scikit-learn para manejar también la validación cruzada.\n",
    "\n",
    "Primero, instanciamos la [clase KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) desde `sklearn.model_selection`:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits, shuffle=False, random_state=None)\n",
    "```\n",
    "\n",
    "donde:\n",
    "\n",
    "- `n_splits` es el número de pliegues que desea utilizar,\n",
    "- `shuffle` se usa para cambiar aleatorizar(revolver) las observaciones en el conjunto de datos,\n",
    "- `random_state` se usa para especificar el valor inicial aleatorio si `shuffle` se establece en `True`.\n",
    "\n",
    "Notará aquí que ningún parámetro depende en absoluto del conjunto de datos. Esto se debe a que la clase KFold devuelve un iterador que usamos junto con la función [cross_val_score()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), también de `sklearn.model_selection`. Juntas, estas 2 funciones nos permiten entrenar y probar de forma compacta utilizando la validación cruzada k-fold:\n",
    "\n",
    "Estos son los parámetros relevantes para la función `cross_val_score`:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(estimador, X, Y, scoring=None, cv=None)\n",
    "```\n",
    "\n",
    "donde:\n",
    "\n",
    "- `estimator` es un modelo sklearn que implementa el método `fit` (por ejemplo, instancia de KNeighborsRegressor),\n",
    "- `X` es la lista o matriz 2D que contiene las funciones en las que desea entrenar,\n",
    "- `y` es una lista que contiene los valores que desea predecir (columna de destino),\n",
    "- `scoring` es una cadena(texto) que describe los criterios de puntuación (lista de valores aceptados <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\" target=\"_blank\">aquí</a>).\n",
    "- `cv` describe el número de pliegues(subconjuntos). Estos son algunos ejemplos de valores aceptados:\n",
    "    - una instancia de la clase `KFold`,\n",
    "    - un número entero que representa el número de pliegues.\n",
    "\n",
    "Dependiendo de los criterios de puntuación que especifique, se devuelve un único valor total para cada pliegue. Aquí está el flujo de trabajo general para realizar la validación cruzada k-fold usando las clases que acabamos de describir:\n",
    "\n",
    "- crear una instancia de la clase de modelo de scikit-learn que desea ajustar,\n",
    "- instanciar la clase `KFold` y usar los parámetros para especificar los atributos de validación cruzada k-fold que desea,\n",
    "- utilice la función `cross_val_score()` para devolver la métrica de puntuación que le interesa.\n",
    "\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Crear una nueva instancia de la clase `KFold` con las siguientes propiedades:\n",
    "    - `5` subconjuntos,\n",
    "    - reproducción aleatoria establecida en 'Verdadero',\n",
    "    - semilla aleatoria establecida en `1` (para que podamos verificar usando la misma semilla),\n",
    "    - asignar a la variable `kf`.\n",
    "- Crear una nueva instancia de la clase `KNeighborsRegressor` y asignarla a `knn`.\n",
    "- Use la función `cross_val_score()` para realizar una validación cruzada k-fold:\n",
    "    - usar la instancia de KNeighborsRegressor `knn`,\n",
    "    - usar la columna `accommodates` para entrenamiento,\n",
    "    - utilizar la columna `price` como la columna de destino(target),\n",
    "    - usar la cadena `neg_mean_squared_error` como el valor del parámetro `scoring`,\n",
    "    - usar `kf` como el valor del parámetro `cv`\n",
    "    - devolver una arreglo de valores MSE (un valor para cada pliegue o subconjunto).\n",
    "- Asigne la lista resultante de valores MSE a `mses`. Luego, tome el valor absoluto seguido de la raíz cuadrada de cada valor de MSE. Luego, calcule el promedio de los valores RMSE resultantes y asigne a `avg_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdb4366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6b7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fea3000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = cross_val_score(estimator=knn, \n",
    "                       X=dc_listings[['accommodates']], \n",
    "                       y=dc_listings['price'], \n",
    "                       scoring='neg_mean_squared_error', \n",
    "                       cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "601c552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.53435892114908\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = np.sqrt(np.abs(mses)).mean()\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36d507",
   "metadata": {},
   "source": [
    "## 7. Explorando diferentes valores de K\n",
    "\n",
    "Elegir el valor `k` correcto al realizar una validación cruzada k-fold es más un arte que una ciencia. Como discutimos anteriormente, un valor `k` de `2` es realmente solo una validación de exclusioń (holdout validation). Por otro lado, establecer `k` igual a `n` (el número de observaciones en el conjunto de datos) se conoce como **leave-one-out cross validation**, o LOOCV para abreviar. Es común tomar `10` como el valor `k` estándar.\n",
    "\n",
    "A continuacioń se muestran los resultados de variar `k` de `3` a `23`. Para cada valor `k`, calculamos y mostramos el valor RMSE promedio en todos los subconjuntos y la desviación estándar de los valores RMSE. A través de los diferentes valores de `k`, parece que el valor RMSE promedio es de alrededor de `129`. Notará que la desviación estándar del RMSE aumenta de aproximadamente `8` a más de `40` a medida que aumentamos el número de pliegues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9049417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 folds: avg RMSE: 126.25643788844208, std RMSE: 2.0462220503302757\n",
      "5 folds: avg RMSE: 132.53435892114908, std RMSE: 10.583222443315243\n",
      "7 folds: avg RMSE: 138.84369852094946, std RMSE: 8.54990777432938\n",
      "9 folds: avg RMSE: 125.79037301186888, std RMSE: 21.189505646505364\n",
      "10 folds: avg RMSE: 130.20650881456987, std RMSE: 23.963967671753206\n",
      "11 folds: avg RMSE: 126.88756397456419, std RMSE: 25.758906948602437\n",
      "13 folds: avg RMSE: 126.70440036154892, std RMSE: 29.05210451728983\n",
      "15 folds: avg RMSE: 130.2583160888913, std RMSE: 30.686863668342742\n",
      "17 folds: avg RMSE: 128.6152830146413, std RMSE: 35.26730539015145\n",
      "19 folds: avg RMSE: 126.7894453710179, std RMSE: 34.63276931942381\n",
      "21 folds: avg RMSE: 126.65264051559065, std RMSE: 37.987028538782695\n",
      "23 folds: avg RMSE: 125.11583067337774, std RMSE: 40.59600544050042\n"
     ]
    }
   ],
   "source": [
    "num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]\n",
    "\n",
    "for fold in num_folds:\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    std_rmse = np.std(rmses)\n",
    "    print(f'{fold} folds: avg RMSE: {avg_rmse}, std RMSE: {std_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e27f3",
   "metadata": {},
   "source": [
    "## 8. Equilibrio entre sesgo y varianza\n",
    "\n",
    "Hemos estado trabajando bajo el supuesto de que un RMSE más bajo siempre significa que un modelo es más preciso. Sin embargo, un modelo tiene dos fuentes de error, **sesgo** y **varianza**.\n",
    "\n",
    "El sesgo o bias describe el error que da como resultado malas suposiciones sobre el algoritmo de aprendizaje. Por ejemplo, suponiendo que solo una característica (variable), como el peso de un automóvil, se relaciona con la eficiencia de combustible de un automóvil, lo llevará a ajustar un modelo de regresión univariante simple que dará como resultado un sesgo alto. La tasa de error será alta ya que la eficiencia de combustible de un automóvil se ve afectada por muchos otros factores además de su peso.\n",
    "\n",
    "La varianza describe el error que ocurre debido a la variabilidad de los valores predichos de un modelo. Si recibimos un conjunto de datos con 1000 características en cada automóvil y usamos cada una de las características para entrenar un modelo de regresión multivariante increíblemente complicado, tendremos un sesgo bajo pero una varianza alta. En un mundo ideal, queremos un sesgo bajo y una varianza baja pero, en realidad, siempre hay tradeoff.\n",
    "\n",
    "La *desviación estándar* de los valores RMSE puede ser un indicador de la **varianza** de un modelo, mientras que el *RMSE promedio* es un indicador del **sesgo** de un modelo. El sesgo y la varianza son las 2 fuentes de error observables en un modelo que podemos controlar indirectamente.\n",
    "\n",
    "\n",
    "<img src=\"figs/bias_variance.png\" width=\"600\" height=\"400\" />\n",
    "\n",
    "Si bien los k-vecinos más cercanos pueden hacer predicciones, no es un modelo matemático. Un modelo matemático suele ser una ecuación que puede existir sin los datos originales, lo que no ocurre con los k vecinos más cercanos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4f201",
   "metadata": {},
   "source": [
    "## 9. Conclusión\n",
    "\n",
    "Exploramos técnicas de validación cruzada más sólidas, como la validación por exlusión y la validación cruzada k-fold.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
