{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34203967",
   "metadata": {},
   "source": [
    "<center><h1>Selección de características</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77477e9a",
   "metadata": {},
   "source": [
    "## 1. Valores faltantes.\n",
    "\n",
    "En el flujo de trabajo de aprendizaje automático, una vez que hemos seleccionado el modelo que queremos usar, el siguiente paso importante es seleccionar las características apropiadas para ese modelo. En esta lección, exploraremos cómo usar la correlación entre las funciones y la columna de destino, la correlación entre las funciones y la varianza de las funciones para seleccionar funciones. Continuaremos trabajando con el mismo conjunto de datos de vivienda de la última lección.\n",
    "\n",
    "Nos centraremos específicamente en la selección de columnas de características que no tengan ningún valor faltante o que no necesiten ser transformadas para ser útiles (por ejemplo, columnas como Año de construcción y Año de remoción/agregación). Exploraremos cómo lidiar con ambos en una lección posterior de este curso.\n",
    "\n",
    "Para comenzar, veamos qué columnas se incluyen en cualquiera de estas dos categorías.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Lea AmesHousing.txt en un dataframe denominado `data`. Asegúrese de usar el delimitador `\\t`.\n",
    "- Cree un dataframe llamado `train`, que contiene las primeras 1460 filas de `data`.\n",
    "- Cree un dataframe llamado `test`, que contiene el resto de las filas `data`.\n",
    "- Seleccione las columnas de números enteros y flotantes de `train` y asígnelas a la variable `numerical_train`.\n",
    "- Quite las siguientes columnas de `numerical_train`:\n",
    "    - `PID` (la identificación del lugar no es útil para modelar)\n",
    "    - `Year Built`\n",
    "    - `Year Remod/Add`\n",
    "    - `Garage Yr Blt`\n",
    "    - `Mo Sold`\n",
    "    - `Yr Sold`\n",
    "- Calcule el número de valores faltantes de cada columna en `numerical_train`. Cree un objeto `pandas.Series` donde el índice se compone de nombres de columna y los valores asociados son el número de valores faltantes:\n",
    "```python\n",
    "Order                0\n",
    "PID                  0\n",
    "MS SubClass          0\n",
    "MS Zoning            0\n",
    "...\n",
    "```\n",
    "- Asigne este objeto `pandas.Series` a `null_series`. Seleccione el subconjunto de `null_series` para mantener solo las columnas sin valores faltantes y asigne el objeto `pandas.Series` resultante a `full_cols_series`.\n",
    "- Muestre `full_cols_series` usando la función `print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f80b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5ffdec",
   "metadata": {},
   "source": [
    "## 2. Correlación de columnas de características con la columna objetivo.\n",
    "\n",
    "Anteriormente, seleccionamos la característica para el modelo de regresión lineal simple al comparar cómo algunas de las características se correlacionan con la columna de destino. Si recuerda, nos enfocamos en 4 características en particular y usamos el método [`pandas.DataFrame.corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) para devolver los coeficientes de correlación entre cada par de columnas. Esto significa que la matriz de correlación para 4 columnas da como resultado 16 valores de correlación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488d9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f436a5f2",
   "metadata": {},
   "source": [
    "El subconjunto de características en las que queremos centrarnos, full_cols_series, contiene 25 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed0ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07640437",
   "metadata": {},
   "source": [
    "La matriz de correlación resultante contendrá 25 * 25 o 625 valores de correlación. Comparar y contrastar tantos valores es increíblemente difícil. En su lugar, centrémonos en cómo las variables se correlacionan con el precio (`SalePrice`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fcf84",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "- Calcule los coeficientes de correlación por pares entre todas las columnas en `train_subset = train[full_cols_series.index]`.\n",
    "\n",
    "- Seleccione solo la columna SalePrice del marco de datos resultante, calcule el valor absoluto de cada término, ordene la Serie resultante por los valores de correlación y asigne a `sorted_corrs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510052ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44f6015",
   "metadata": {},
   "source": [
    "## 3. Mapa de calor de matriz de correlación.\n",
    "Ahora tenemos una lista decente de características candidatas para usar en nuestro modelo, ordenadas según su correlación con la columna `SalePrice`. Por ahora, mantengamos solo las características que tienen una correlación de 0.3 o superior. Este corte es un poco arbitrario y, en general, es una buena idea experimentar con este corte. Por ejemplo, puedes entrenar y probar modelos usando diferentes puntos de corte y ver dónde deja de mejorar el modelo.\n",
    "\n",
    "Lo siguiente que debemos buscar es la posible **colinealidad** entre algunas de estas variables. La colinealidad se da cuando 2 variables (columnas) están altamente correlacionadas y corren el riesgo de duplicar información. Si tenemos 2 características que transmiten la misma información usando 2 medidas o métricas diferentes, no necesitamos conservar ambas.\n",
    "\n",
    "Si bien podemos verificar la colinealidad entre 2 columnas usando la matriz de correlación, corremos el riesgo de sobrecarga de información. En su lugar, podemos generar un mapa de [calor de matriz de correlación](http://seaborn.pydata.org/examples/heatmap_annotation.html) usando Seaborn para comparar visualmente las correlaciones y buscar correlaciones de características por pares. Debido a que estamos buscando valores atípicos en el mapa de calor, esta representación visual es más fácil.\n",
    "\n",
    "Así es como se ve el mapa de calor de la matriz de correlación de ejemplo de la documentación:\n",
    "\n",
    "<img src=\"figs/correlation_heatmap_matrix.png\" widht=\"800\" height=\"600\"/>\n",
    "\n",
    "\n",
    "Para generar un mapa de calor de matriz de correlación, debemos pasar el dataframe que contiene la matriz de correlación como un dataframe a la función `seaborn.heatmap()`.\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Seleccione solo las columnas en `sorted_corrs` con una correlación superior a 0,3 y asígnelas a `strong_corrs`.\n",
    "- Filtre `train_subset` utilizando los índices de `strong_corrs` y almacene las correlaciones en `corrmat`.\n",
    "- Use la función [`seaborn.heatmap`](http://seaborn.pydata.org/generated/seaborn.heatmap.html) para generar un mapa de calor de matriz de correlación para las columnas en strong_corrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488a293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cba9186b",
   "metadata": {},
   "source": [
    "## 4. Modelo de entrenamiento y prueba.\n",
    "Según el mapa de calor de la matriz de correlación, podemos decir que los siguientes pares de columnas están fuertemente correlacionados:\n",
    "\n",
    "- Gr Liv Area y TotRms AbvGrd\n",
    "- Garage Area y Garage Cars\n",
    "\n",
    "Si leemos las descripciones de estas columnas de la documentación de datos, podemos decir que cada par de columnas refleja información muy similar. Debido a que `Gr Liv Area` y `Garage Area` son variables continuas que captan más matices, eliminemos `TotRms AbvGrd` y `Garage Cars`.\n",
    "\n",
    "Lo último que debemos hacer es confirmar que el conjunto de prueba no contiene valores faltantes para estas columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fba10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d789d956",
   "metadata": {},
   "source": [
    "Parece que el conjunto de prueba tiene **una fila** en la que falta un valor para `Garage Area`. Quitemos esta fila por ahora. Finalmente, entrenemos y probemos un modelo usando estas columnas para ver cómo les va."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027339dd",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "- Filtre el dataframe `test` para que solo contenga las columnas de `final_corr_cols.index`. Luego, quite la fila que contiene los valores faltantes y asigne el resultado a `clean_test`\n",
    "- Cree un modelo de regresión lineal.\n",
    "- Calcule el RMSE en los conjuntos de prueba y entrenamiento.\n",
    "- Asigne el RMSE de tren a `train_rmse` y el RMSE de prueba a `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660727a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d57f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85359963",
   "metadata": {},
   "source": [
    "## 5. Eliminación de características de baja varianza.\n",
    "La última técnica que exploraremos es eliminar características con poca variación. Cuando los valores de una columna de características tienen una varianza baja, no contribuyen significativamente a la capacidad predictiva del modelo. En el extremo, imaginemos una columna con una varianza de 0. Esto significaría que todos los valores en esa columna **son exactamente iguales**. Esto significa que la columna no es informativa y no ayudará al modelo a hacer mejores predicciones.\n",
    "\n",
    "Para hacer comparaciones de manzanas con manzanas entre columnas, necesitamos reescalar todas las columnas para que varíen entre 0 y 1. Esto se conoce como escalado mínimo-máximo (min.max) o [reescalado](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling). Aquí está la fórmula para cambiar la escala:\n",
    "\n",
    "$$\\dfrac{x - \\min(x)} {\\max(x) - \\min(x)}$$\n",
    "\n",
    "donde\n",
    "\n",
    "- $x$ es un valor individual\n",
    "- $\\min(x)$ es el valor mínimo en la columna a la que pertenece $x$\n",
    "- $\\max(x)$ es el valor máximo en la columna a la que pertenece $x$\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Seleccione las columnas en `features` del dataframe de entrenamiento. Vuelva a escalar cada una de las columnas para que los valores oscilen entre `0` y `1`, utilizando `train[features]` en lugar de $x$  en la fórmula anterior. Asigne el resultado a `unit_train`.\n",
    "- Calcule y muestre los valores mínimo y máximo de la columna de `unit_train` para asegurarse de que todos los valores van de `0` a `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048d5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf495801",
   "metadata": {},
   "source": [
    "## 6. Modelo Final.\n",
    "Calculemos las varianzas y eliminemos las columnas con la varianza más baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf47bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "431f8f67",
   "metadata": {},
   "source": [
    "Vemos que `Open Porch SF` es la columna con la varianza más baja y está más alejada de `Full Bath` que `Full Bath` de la siguiente.\n",
    "\n",
    "Para concluir este ejercicio, eliminemos `Open Porch SF` y entrenemos y probemos un modelo usando las funciones restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cd978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43da8c13",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "- Elimina `Open Porch SF` de las características.\n",
    "- Cree un modelo de regresión lineal utilizando las funciones restantes.\n",
    "- Calcule el RMSE en los conjuntos de prueba y entrenamiento.\n",
    "    - Use `clean_test` \n",
    "- Asigne el RMSE de entrenamiento a `train_rmse_2` y el RMSE de prueba a `test_rmse_2`.\n",
    "- Muestra ambos valores RMSE usando la función `print()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3ba00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
