{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbb20d4",
   "metadata": {},
   "source": [
    "<center><h1>Proyecto: Predicción de precios de venta de casas</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0508e3",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introducción.\n",
    "Comenzamos desarrollando la intuición para el aprendizaje basado en modelos, exploramos cómo funcionaba el modelo de regresión lineal, comprendimos cómo funcionaban los dos enfoques diferentes para el ajuste de modelos y algunas técnicas para limpiar, transformar y seleccionar características. \n",
    "\n",
    "Trabajaremos con datos de vivienda de la ciudad de Ames, Iowa, Estados Unidos, de 2006 a 2010. Puede leer más sobre por qué se recopilaron los datos <a href=\"https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627\" target=\"_blank\">aquí</a>. También puede leer sobre las diferentes columnas en la descripción.\n",
    "\n",
    "Comencemos analizando el conjunto de rutinas que nos permitirá iterar rápidamente en diferentes modelos:\n",
    "\n",
    "<a id=\"fig:pipeline\"></a>\n",
    "<img src=\"figs/pipeline.svg\" height=\"150\" width=\"200\"  alt=\"pipeline\"/>\n",
    "\n",
    "### Ejercicio\n",
    "- Importe pandas, matplotlib y numpy. Importe también las clases que necesita de scikit-learn.\n",
    "- Lea `AmesHousing.tsv` en un DataFrame de pandas.\n",
    "- Para las siguientes funciones, recomendamos crearlas en las primeras celdas del notebook. De esta manera, puede agregar celdas al final del notebook para hacer experimentos y actualizar las funciones en estas celdas.\n",
    "    - Cree una función llamada `transform_features()` que, por ahora, solo devuelve dataframe de `train`.\n",
    "    - Cree una función llamada `select_features()` que, por ahora, solo devuelve las columnas `Gr Liv Area` y `SalePrice` del dataframe `train`.\n",
    "    - Cree una función llamada `train_and_test()` que, por ahora:\n",
    "        - Selecciona las primeras `1460` filas de `data` y las asigna a `train`.\n",
    "        - Selecciona las filas restantes de `data` y asignar a `test`.\n",
    "        - Entrena un modelo utilizando todas las columnas numéricas excepto la columna `SalePrice` (la columna target) del dataframe devuelto por `select_features()`\n",
    "        - Prueba el modelo en el conjunto de prueba y devuelve el valor RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b1153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5bdca47",
   "metadata": {},
   "source": [
    "## 2. Ingeniería de características.\n",
    "Ahora comencemos a eliminar características con muchos valores faltantes, profundizando en características categóricas potenciales y transformando texto y columnas numéricas. Actualice `transform_features()` para que se elimine cualquier columna del dataframe con más del 25 % (u otro valor límite) de valores faltantes. También debe eliminar cualquier columna que no aportan información sobre la venta (por ejemplo, como el año en que ocurrió la venta). En general, el objetivo de esta función es:\n",
    "\n",
    "- eliminar variables que no queremos usar en el modelo, solo en función de la cantidad de valores faltantes o falta de información\n",
    "- transformar características en el formato adecuado (numérico a categórico, escalar numérico, completar valores faltantes, etc.)\n",
    "- crear nuevas variables combinando otras variables (características)\n",
    "\n",
    "Se recomienda familiarizarse más con las columnas restantes leyendo la documentación, determinando qué transformaciones son necesarias (si las hay) y más. El éxito en el modelado predictivo depende en gran medida de la calidad de las variables que tenga el modelo. Las bibliotecas como scikit-learn demuestran que probar y modificar muchos modelos diferentes sea rápido y fácil, pero limpiar, seleccionar y transformar características sigue siendo más un arte que requiere un poco de ingenio humano.\n",
    "\n",
    "### Ejercicio\n",
    "- Agregue algunas celdas para explorar y experimentar con diferentes variables (antes de reescribir estas funciones).\n",
    "- La función `transform_features()` no debería modificar `train` y, en su lugar, devolver nuevo dataframe por completo. De esta manera, podemos seguir usando `train` en las celdas de experimentación.\n",
    "- ¿Qué columnas contienen menos del 5 % de valores perdidos?\n",
    "    - Para las columnas numéricas que cumplan con este criterio, completemos los valores faltantes usando el valor más popular para esa columna.\n",
    "- ¿Qué nuevas variables podemos crear, que capturen mejor la información en algunas de las variables?\n",
    "    - Un ejemplo de esto sería la característica `years_until_remod` que creamos anteriormente.\n",
    "- ¿Qué columnas deben eliminarse por otras razones?\n",
    "    - ¿Qué columnas no son útiles para el aprendizaje automático?\n",
    "    - ¿Qué columnas no aportan información sobre la venta final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a39895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa4e4242",
   "metadata": {},
   "source": [
    "## 3. Selección de características.\n",
    "Después de limpiat y transformar muchas de las características del conjunto de datos, es hora de pasar a la selección de características para características numéricas.\n",
    "\n",
    "### Ejercicio\n",
    "- Genere un mapa de calor con la matriz de correlación de las características numéricas en el conjunto de datos de entrenamiento.\n",
    "    - ¿Qué características se correlacionan fuertemente con nuestra columna objetivo, `SalePrice`?\n",
    "    - Calcule los coeficientes de correlación para las columnas que parecen correlacionarse bien con `SalePrice`. Debido a que contamos un [esquema de trabajo](#fig:pipeline), es fácil probar diferentes variables (características) y ver qué variables dan como resultado una mejor puntuación en la validación cruzada.\n",
    "\n",
    "- ¿Qué columnas del dataframe deben convertirse al tipo de datos categóricos? Todas las columnas que se pueden categorizar como variables nominales son candidatas para convertirse en categóricas. Aquí hay algunas otras cosas en las que debe pensar:\n",
    "    - Si una columna categórica tiene cientos de valores (o categorías) únicos, ¿debería conservarla? Cuando codifique de forma ficticia esta columna, será necesario volver a agregar cientos de columnas al dataframe.\n",
    "    - ¿Qué columnas categóricas tienen algunos valores únicos, pero más del 95 % de los valores de la columna pertenecen a una categoría específica? Esto sería similar a una característica numérica de baja varianza (sin variabilidad en los datos para que el modelo los capture).\n",
    "\n",
    "- ¿Qué columnas actualmente son numéricas pero deben codificarse como categóricas (porque los números no tienen ningún significado semántico)?\n",
    "\n",
    "- ¿En que forma podemos explorar columnas categóricas que \"se correlacionan\" bien con `SalePrice`?\n",
    "    - Lea <a href=\"https://machinelearningmastery.com/feature-selection-machine-learning-python/\" target=\"_blank\">este blog</a> para conocer algunas estrategias.\n",
    "\n",
    "- Actualice la lógica de la función `select_features()`. Esta función debe aceptar los dataframes modificados de prueba y entrenamiento que se obtuvieron de la función `transform_features()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdb7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1421547",
   "metadata": {},
   "source": [
    "## 4. Entrenar y probar.\n",
    "Para la parte final de nuestro [esquema de trabajo](#fig:pipeline), entrenamiento y pruebas. Al iterar sobre diferentes características, es una buena idea usar una validación simple. Agreguemos un parámetro llamado `k` que controla el tipo de validación cruzada que ocurre.\n",
    "\n",
    "### Ejercicio\n",
    "- El parámetro `k` opcional debe aceptar valores enteros, con un valor predeterminado de `0`.\n",
    "- Cuando `k` sea igual a `0`, realice la validación de exlusión (lo que ya implementamos):\n",
    "    - Seleccione las primeras `1460` filas y asígnelas a `train`.\n",
    "    - Seleccione las filas restantes y asígnelas a `test`.\n",
    "    - Entrena sobre `train` y prueba sobre `test`.\n",
    "    - Calcule y retorne el RMSE.\n",
    "\n",
    "- Cuando `k` es igual a `1`, realice una validación cruzada simple:\n",
    "    - Aleatoriza el orden de las filas en el dataframe.\n",
    "    - Seleccione las primeras `1460` filas y asígnelas a `fold_one`.\n",
    "    - Seleccione las filas restantes y asígnelas a `fold_two`.\n",
    "    - Entrena en fold_one y prueba en `fold_two`.\n",
    "    - Entrena en fold_two y prueba en `fold_one`.\n",
    "    - Calcule y devuelva el RMSE promedio.\n",
    "\n",
    "- Cuando `k` es mayor que `0`, implemente la validación cruzada k-fold usando `k` subconjuntos:\n",
    "    - Realice la validación cruzada de k-fold usando `k` subconjuntos.\n",
    "    - Calcule el valor promedio de RMSE y devuelva este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230aaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
